{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5bfa5b-7b78-44e8-b7df-d7b0e4077359",
   "metadata": {},
   "source": [
    "# Tables\n",
    "- Number of all and valid gages: US, HUC2, aquifer\n",
    "- Distribution of HMF metrics: US, HUC2, aquifer\n",
    "- Gages with the highest annual volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efa34af-e99e-423e-a381-cfdbc3989abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Src.func_ko' from 'C:\\\\Users\\\\kondris\\\\Documents\\\\GitHub\\\\HighMagFlows_EPA_Project\\\\Src\\\\func_ko.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "#import contextily as cx\n",
    "import requests\n",
    "import calendar\n",
    "from importlib import reload\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Point\n",
    "from io import StringIO\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# USGS Data retreival tool\n",
    "from dataretrieval import nwis, utils, codes\n",
    "\n",
    "# Custom modules are imported in multiple locations to faciliate easy reloading when edits are made to their respective files\n",
    "import Src.classes as cl\n",
    "import Src.func_ko as fn\n",
    "reload(cl)\n",
    "reload(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94855cb9-b780-42ad-beff-bc68c3c3f64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100907254361798"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km3_to_maf = (1000)**3 * (3.28)**3 / (43560) / 1000000\n",
    "1*km3_to_maf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcdda1d-1cba-4cca-967b-5a88a2a9e503",
   "metadata": {},
   "source": [
    "### Import national metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187fe22c-13ed-417f-9c23-d81b7a484aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All gages - National metrics dfs\n",
    "# data_paths = {\n",
    "#     '30_90': 'Prelim_Data/National_Metrics/National_Metrics_30_90.xlsx',\n",
    "#     '50_90': 'Prelim_Data/National_Metrics/National_Metrics_50_90.xlsx',\n",
    "#     '30_95': 'Prelim_Data/National_Metrics/National_Metrics_30_95.xlsx',\n",
    "#     '50_95': 'Prelim_Data/National_Metrics/National_Metrics_50_95.xlsx'    \n",
    "# }\n",
    "\n",
    "#dfs_metrics = {key: pd.read_excel(path, sheet_name='site_metrics') for key, path in data_paths.items()}\n",
    "\n",
    "data_paths = {\n",
    "    '30_90': 'Prelim_Data/National_Metrics/Station_names/National_Metrics_30_90.xlsx',\n",
    "    '50_90': 'Prelim_Data/National_Metrics/Station_names/National_Metrics_50_90.xlsx',\n",
    "    '30_95': 'Prelim_Data/National_Metrics/Station_names/National_Metrics_30_95.xlsx',\n",
    "    '50_95': 'Prelim_Data/National_Metrics/Station_names/National_Metrics_50_95.xlsx'    \n",
    "}\n",
    "\n",
    "dfs_valid = {key: pd.read_excel(path) for key, path in data_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25faeea-09ea-4886-bc3a-4fe320de9f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Converts site_no to strings\n",
    "# date_ranges = ['30', '50']\n",
    "# percentiles = ['90', '95']\n",
    "# for date_range in date_ranges:\n",
    "#     for percentile in percentiles: \n",
    "#         # Assuming df is your DataFrame and 'column_name' is the name of the column with numbers\n",
    "#         dfs_metrics[f'{date_range}_{percentile}']['site_no'] = dfs_metrics[f'{date_range}_{percentile}']['site_no'].astype(str)  # Convert numbers to strings\n",
    "\n",
    "#         # Add leading '0' to numbers with 7 digits\n",
    "#         dfs_metrics[f'{date_range}_{percentile}']['site_no'] = dfs_metrics[f'{date_range}_{percentile}']['site_no'].apply(lambda x: '0' + x if len(x) == 7 else x)\n",
    "\n",
    "# Converts site_no to strings\n",
    "date_ranges = ['30', '50']\n",
    "percentiles = ['90', '95']\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles: \n",
    "        # Assuming df is your DataFrame and 'column_name' is the name of the column with numbers\n",
    "        dfs_valid[f'{date_range}_{percentile}']['site_no'] = dfs_valid[f'{date_range}_{percentile}']['site_no'].astype(str)  # Convert numbers to strings\n",
    "\n",
    "        # Add leading '0' to numbers with 7 digits\n",
    "        dfs_valid[f'{date_range}_{percentile}']['site_no'] = dfs_valid[f'{date_range}_{percentile}']['site_no'].apply(lambda x: '0' + x if len(x) == 7 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcafc6ba-4366-4240-b954-84c558250317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Valid gages - National metrics dfs\n",
    "# dfs_valid = {}\n",
    "# for date_range in date_ranges:\n",
    "#     for percentile in percentiles: \n",
    "#         dfs_valid[f'{date_range}_{percentile}'] = dfs_metrics[f'{date_range}_{percentile}'][dfs_metrics[f'{date_range}_{percentile}']['valid'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250d8598-aa92-4a99-bdcf-d39559fa6b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        3\n",
       "2        3\n",
       "3        3\n",
       "4        3\n",
       "        ..\n",
       "4237    14\n",
       "4238    14\n",
       "4239    14\n",
       "4240    14\n",
       "4241    17\n",
       "Name: huc2_code, Length: 4242, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_valid['30_90']['huc2_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d589c5c-36a7-438a-8c52-40eee5e865c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-06-05 00:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def convert_day_of_year(day_number, base_year=2023):\n",
    "    # Calculate the start date (October 1 of the base year)\n",
    "    start_date = pd.to_datetime(f\"{base_year}-10-01\")\n",
    "    \n",
    "    # Adjust the day number by subtracting 1 to account for the start date\n",
    "    adjusted_day_number = day_number - 0\n",
    "    \n",
    "    # Calculate the final date by adding the adjusted day number to the start date\n",
    "    final_date = start_date + pd.DateOffset(days=adjusted_day_number)\n",
    "    \n",
    "    return final_date\n",
    "\n",
    "convert_day_of_year(248)\n",
    "\n",
    "# for date_range in date_ranges:\n",
    "#     for percentile in percentiles: \n",
    "#         dfs_valid[f'{date_range}_{percentile}']['timing'] = pd.to_numeric(dfs_valid[f'{date_range}_{percentile}']['timing'])\n",
    "#         dfs_valid[f'{date_range}_{percentile}']['timing'] = dfs_valid[f'{date_range}_{percentile}']['timing'].round()\n",
    "#         dfs_valid[f'{date_range}_{percentile}']['com_date'] = convert_day_of_year(dfs_valid[f'{date_range}_{percentile}']['timing'].apply(convert_day_of_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10001215-b73b-4009-8d4f-08c673d88c6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sort by HUC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e09ff89e-6f48-4d46-a285-cf80c41bd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'huc2_all_gages_{date_range}_{percentile}.xlsx'\n",
    "        dfs_valid[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee71d3-0a65-46fb-becd-c0b94e2ad541",
   "metadata": {},
   "source": [
    "### Tables for mean HMF metrics at huc2 gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "710fd2e6-f138-4e24-9dc1-bd1501535906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gages in CONUS (30-year record): 4242\n",
      "Number of gages in CONUS (50-year record): 3314\n"
     ]
    }
   ],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'huc2_code']\n",
    "print('Number of gages in CONUS (30-year record):', len(dfs_valid[f'30_90']))\n",
    "print('Number of gages in CONUS (50-year record):', len(dfs_valid[f'50_90']))\n",
    "\n",
    "df_mean_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('huc2_code').mean()\n",
    "        df_mean_metrics[f'{date_range}_{percentile}']['type'] = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "554646ff-a8a1-4502-9fef-9b6b7127d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'huc2_hmf_metrics_mean_{date_range}_{percentile}.xlsx'\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f19667-11e3-440b-8646-b7429a4a305c",
   "metadata": {},
   "source": [
    "### Tables for min HMF metrics at huc2 gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "977875ec-dc67-455e-ad38-ad6089df822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'huc2_code']\n",
    "#print('Number of gages in 25 most pumped aqs:', len(dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25.values())]))\n",
    "\n",
    "df_min_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_min_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('huc2_code').min()\n",
    "        df_min_metrics[f'{date_range}_{percentile}']['type'] = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2af15bb5-11a5-46d9-9259-339ea654442c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'huc2_hmf_metrics_min_{date_range}_{percentile}.xlsx'\n",
    "        df_min_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc245d-4a29-4ac7-b3a3-efa2f42d970f",
   "metadata": {},
   "source": [
    "### Tables for max HMF metrics at ALL aquifer gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ac3b25c2-0e5e-4846-9ca3-37f9d693634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'huc2_code']\n",
    "#print('Number of gages in 25 most pumped aqs:', len(dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25.values())]))\n",
    "\n",
    "df_max_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_max_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('huc2_code').max()\n",
    "        df_max_metrics[f'{date_range}_{percentile}']['type'] = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e318fd98-d465-4c8d-b26d-8c051e1c5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'huc2_hmf_metrics_max_{date_range}_{percentile}.xlsx'\n",
    "        df_max_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf83141-631a-483e-a407-d10294d9d68c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combine max, mean, and min tables and save as one excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fc5c1b22-4017-4b6c-ab44-92adfbb4523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        # Combine the three dataframes\n",
    "        df_combined = pd.concat([df_min_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_mean_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_max_metrics[f'{date_range}_{percentile}']])\n",
    "\n",
    "        # Sort the combined dataframe to ensure the order is min, mean, max for each aquifer\n",
    "        df_combined = df_combined.sort_values(by=['huc2_code', 'type'])\n",
    "\n",
    "        # Save the combined dataframe to a new Excel file\n",
    "        file_name = f'huc2_hmf_metrics_{date_range}_{percentile}.xlsx'\n",
    "        df_combined.to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ac926-d2c2-4a60-b7c6-f92f81c014ed",
   "metadata": {},
   "source": [
    "### Compare percentiles and date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea398c26-62bf-4307-9c74-d7033565074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\4053928047.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  huc2_hmf_metrics_30_90['type'] = huc2_hmf_metrics_30_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\4053928047.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  huc2_hmf_metrics_30_95['type'] = huc2_hmf_metrics_30_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\4053928047.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  huc2_hmf_metrics_50_90['type'] = huc2_hmf_metrics_50_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\4053928047.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  huc2_hmf_metrics_50_95['type'] = huc2_hmf_metrics_50_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n"
     ]
    }
   ],
   "source": [
    "huc2_hmf_metrics_30_90 = pd.read_excel('Tables/huc2_hmf_metrics_30_90.xlsx')\n",
    "huc2_hmf_metrics_30_90['type'] = huc2_hmf_metrics_30_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "huc2_hmf_metrics_30_95 = pd.read_excel('Tables/huc2_hmf_metrics_30_95.xlsx')\n",
    "huc2_hmf_metrics_30_95['type'] = huc2_hmf_metrics_30_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "huc2_hmf_metrics_50_90 = pd.read_excel('Tables/huc2_hmf_metrics_50_90.xlsx')\n",
    "huc2_hmf_metrics_50_90['type'] = huc2_hmf_metrics_50_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "huc2_hmf_metrics_50_95 = pd.read_excel('Tables/huc2_hmf_metrics_50_95.xlsx')\n",
    "huc2_hmf_metrics_50_95['type'] = huc2_hmf_metrics_50_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18ce22e1-1e5b-46e0-85ba-c7027046e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "huc2_list = huc2_hmf_metrics_30_90['huc2_code'].tolist()\n",
    "type_list = huc2_hmf_metrics_30_90['type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59ed4624-ed39-496c-89cd-80250b184d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "huc2_hmf_metrics_30_90_50 = ((huc2_hmf_metrics_30_90 - huc2_hmf_metrics_50_90) / huc2_hmf_metrics_30_90) * 100\n",
    "huc2_hmf_metrics_30_90_50['huc2_code'] = huc2_list\n",
    "huc2_hmf_metrics_30_90_50['type'] = type_list\n",
    "file_name = f'huc2_hmf_metrics_30_90_50.xlsx'\n",
    "huc2_hmf_metrics_30_90_50.to_excel('Tables/'+file_name)\n",
    "\n",
    "huc2_hmf_metrics_30_90_95 = ((huc2_hmf_metrics_30_90 - huc2_hmf_metrics_30_95) / huc2_hmf_metrics_30_90) * 100\n",
    "huc2_hmf_metrics_30_90_95['huc2_code'] = huc2_hmf_metrics_30_90['huc2_code']\n",
    "huc2_hmf_metrics_30_90_95['type'] = type_list\n",
    "file_name = f'huc2_hmf_metrics_30_90_95.xlsx'\n",
    "huc2_hmf_metrics_30_90_95.to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8073b199-5d18-4b21-8271-ff90baf3cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#huc2_hmf_metrics_30_90_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e7ba-dfed-4ceb-979f-d7b6fb33c317",
   "metadata": {},
   "source": [
    "## Sort by AQUIFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c3d7d4b-b905-45cf-8139-d14a46e5fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "## Aquifer gages\n",
    "dfs_valid['30_90']['within_aq'].unique()\n",
    "\n",
    "aq_names_25_list = ['Southeastern Coastal Plain aquifer system',\n",
    "       'Coastal lowlands aquifer system', 'Floridan aquifer system',\n",
    "       'Valley and Ridge aquifers',\n",
    "       'Piedmont and Blue Ridge crystalline-rock aquifers',\n",
    "       'Mississippi embayment aquifer system',\n",
    "       'Basin and Range basin-fill aquifers',\n",
    "       'Mississippi River Valley alluvial aquifer',\n",
    "       'Pacific Northwest basin-fill aquifers',\n",
    "       'California Coastal Basin aquifers',\n",
    "       'Central Valley aquifer system',\n",
    "       'Pacific Northwest basaltic-rock aquifers',\n",
    "       'Northern Atlantic Coastal Plain aquifer system',\n",
    "       'Surficial aquifer system', 'Biscayne aquifer',\n",
    "       'Northern Rocky Mountains Intermontane Basins aquifer system',\n",
    "       'Snake River Plain basaltic-rock aquifers',\n",
    "       'Columbia Plateau basaltic-rock aquifers',\n",
    "       'Cambrian-Ordovician aquifer system', 'Silurian-Devonian aquifers',\n",
    "       'Lower Cretaceous aquifers', 'High Plains aquifer',\n",
    "       'Rio Grande aquifer system', 'Edwards-Trinity aquifer system',\n",
    "       'Willamette Lowland basin-fill aquifers']\n",
    "\n",
    "aq_names_10_list = {'High Plains aquifer',\n",
    "                'Mississippi River Valley alluvial aquifer',\n",
    "                'Central Valley aquifer system',\n",
    "                'Basin and Range basin-fill aquifers',\n",
    "                'Floridan aquifer system',\n",
    "                'Snake River Plain basaltic-rock aquifers',\n",
    "                'Coastal lowlands aquifer system',\n",
    "                'California Coastal Basin aquifers', \n",
    "                'Pacific Northwest basin-fill aquifers',\n",
    "                'Northern Atlantic Coastal Plain aquifer system'}\n",
    "\n",
    "\n",
    "dfs_aq = {}\n",
    "date_ranges = ['30', '50']\n",
    "percentiles = ['90', '95']\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles: \n",
    "        dfs_aq[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25)]\n",
    "print(len(dfs_aq['30_90']))\n",
    "\n",
    "dfs_aq_10 = {}\n",
    "date_ranges = ['30', '50']\n",
    "percentiles = ['90', '95']\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles: \n",
    "        dfs_aq_10[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_10)]\n",
    "print(len(dfs_aq_10['30_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c569b6b-8d5f-40a5-a674-bed3ef3c28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dfs_aq['30_90']['within_aq'].value_counts()\n",
    "counts_df = counts.reset_index()\n",
    "counts_df.columns = ['within_aq', 'count']\n",
    "counts_df.to_excel('Tables/aq_counts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9ecc9ad-61a7-488d-8e2c-3c5312279186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_all_gages_{date_range}_{percentile}.xlsx'\n",
    "        dfs_aq[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)\n",
    "        \n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'10_aq_all_gages_{date_range}_{percentile}.xlsx'\n",
    "        dfs_aq_10[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb75a17-b64a-409f-a1e8-efe8306b4bfe",
   "metadata": {},
   "source": [
    "### Tables for mean HMF metrics at ALL aquifer gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31fa8f89-fbc0-4fbe-93fb-c95d14d23e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gages in 25 most pumped aqs: 1299\n"
     ]
    }
   ],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'within_aq']\n",
    "print('Number of gages in 25 most pumped aqs:', len(dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25.values())]))\n",
    "\n",
    "df_mean_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('within_aq').mean()\n",
    "        df_mean_metrics[f'{date_range}_{percentile}']['type'] = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0fd9d5ca-ce71-4318-946d-5d2b84f31a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_all_mean_{date_range}_{percentile}.xlsx'\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31884c-be5e-47db-8a10-f5dc90ff8675",
   "metadata": {},
   "source": [
    "### Tables for min HMF metrics at ALL aquifer gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56ac6ce0-8451-4dc7-b40d-fd7cb44202b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gages in 25 most pumped aqs: 1299\n"
     ]
    }
   ],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'within_aq']\n",
    "print('Number of gages in 25 most pumped aqs:', len(dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25.values())]))\n",
    "\n",
    "df_min_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_min_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('within_aq').min()\n",
    "        df_min_metrics[f'{date_range}_{percentile}']['type'] = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d97150b7-77f0-4df6-a476-5b89d286ba8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_all_min_{date_range}_{percentile}.xlsx'\n",
    "        df_min_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa271bc4-cfed-47e8-b82c-24bdb53abc3d",
   "metadata": {},
   "source": [
    "### Tables for max HMF metrics at ALL aquifer gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78de96e9-5e62-4418-ba80-8bdaef3ca82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gages in 25 most pumped aqs: 1299\n"
     ]
    }
   ],
   "source": [
    "# All gages in each aquifer\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'within_aq']\n",
    "print('Number of gages in 25 most pumped aqs:', len(dfs_valid[f'{date_range}_{percentile}'].loc[dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25.values())]))\n",
    "\n",
    "df_max_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_max_metrics[f'{date_range}_{percentile}'] = dfs_valid[f'{date_range}_{percentile}'][metric_list].groupby('within_aq').max()\n",
    "        df_max_metrics[f'{date_range}_{percentile}']['type'] = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3e1e96f-0cb0-49cd-afdc-5d40e39cfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_all_max_{date_range}_{percentile}.xlsx'\n",
    "        df_max_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80a06e-f593-4553-b284-eb0aa39b6bc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combine max, mean, and min tables and save as one excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5238d29f-b2dd-4c60-9320-807746a95f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        # Combine the three dataframes\n",
    "        df_combined = pd.concat([df_min_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_mean_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_max_metrics[f'{date_range}_{percentile}']])\n",
    "\n",
    "        # Sort the combined dataframe to ensure the order is min, mean, max for each aquifer\n",
    "        df_combined = df_combined.sort_values(by=['within_aq', 'type'])\n",
    "\n",
    "        # Save the combined dataframe to a new Excel file\n",
    "        file_name = f'aq_hmf_metrics_all_{date_range}_{percentile}.xlsx'\n",
    "        df_combined.to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d41b1d5-7865-41d0-b16f-4d03cbe54ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\1868654585.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq_hmf_metrics_all_30_90['type'] = aq_hmf_metrics_all_30_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\1868654585.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq_hmf_metrics_all_30_95['type'] = aq_hmf_metrics_all_30_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\1868654585.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq_hmf_metrics_all_50_90['type'] = aq_hmf_metrics_all_50_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
      "C:\\Users\\kondris\\AppData\\Local\\Temp\\ipykernel_224532\\1868654585.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aq_hmf_metrics_all_50_95['type'] = aq_hmf_metrics_all_50_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n"
     ]
    }
   ],
   "source": [
    "aq_hmf_metrics_all_30_90 = pd.read_excel('Tables/aq_hmf_metrics_all_30_90.xlsx')\n",
    "aq_hmf_metrics_all_30_90['type'] = aq_hmf_metrics_all_30_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "aq_hmf_metrics_all_30_95 = pd.read_excel('Tables/aq_hmf_metrics_all_30_95.xlsx')\n",
    "aq_hmf_metrics_all_30_95['type'] = aq_hmf_metrics_all_30_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "aq_hmf_metrics_all_50_90 = pd.read_excel('Tables/aq_hmf_metrics_all_50_90.xlsx')\n",
    "aq_hmf_metrics_all_50_90['type'] = aq_hmf_metrics_all_50_90['type'].replace({'max': 1, 'mean': 2, 'min': 3})\n",
    "\n",
    "aq_hmf_metrics_all_50_95 = pd.read_excel('Tables/aq_hmf_metrics_all_50_95.xlsx')\n",
    "aq_hmf_metrics_all_50_95['type'] = aq_hmf_metrics_all_50_95['type'].replace({'max': 1, 'mean': 2, 'min': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4dae0dab-7c0f-4e3e-a81a-9e9252a03e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_list = aq_hmf_metrics_all_30_90['within_aq'].tolist()\n",
    "type_list = aq_hmf_metrics_all_30_90['type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8eca9690-2819-44d0-9814-a904546d1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_hmf_metrics_all_30_90 = aq_hmf_metrics_all_30_90.drop('within_aq', axis=1)\n",
    "aq_hmf_metrics_all_50_90 = aq_hmf_metrics_all_50_90.drop('within_aq', axis=1)\n",
    "aq_hmf_metrics_all_30_95 = aq_hmf_metrics_all_30_95.drop('within_aq', axis=1)\n",
    "\n",
    "aq_hmf_metrics_all_30_90_50 = ((aq_hmf_metrics_all_30_90 - aq_hmf_metrics_all_50_90) / aq_hmf_metrics_all_30_90) * 100\n",
    "aq_hmf_metrics_all_30_90_50['within_aq'] = aq_list\n",
    "aq_hmf_metrics_all_30_90_50['type'] = type_list\n",
    "file_name = f'aq_hmf_metrics_all_30_90_50.xlsx'\n",
    "aq_hmf_metrics_all_30_90_50.to_excel('Tables/'+file_name)\n",
    "\n",
    "aq_hmf_metrics_all_30_90_95 = ((aq_hmf_metrics_all_30_90 - aq_hmf_metrics_all_30_95) / aq_hmf_metrics_all_30_90) * 100\n",
    "aq_hmf_metrics_all_30_90_95['within_aq'] = aq_list\n",
    "aq_hmf_metrics_all_30_90_95['type'] = type_list\n",
    "file_name = f'aq_hmf_metrics_all_30_90_95.xlsx'\n",
    "aq_hmf_metrics_all_30_90_95.to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8fb8d-224d-4e3f-9d98-61c81f7054d0",
   "metadata": {},
   "source": [
    "### Highest gages of a certain metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800160cd-1ab8-48bc-8b24-8652e62176d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_hmf</th>\n",
       "      <th>station_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>8.263256</td>\n",
       "      <td>COLUMBIA RIVER AT THE DALLES, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>5.576072</td>\n",
       "      <td>Missouri River at Sioux City, IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>5.218621</td>\n",
       "      <td>Missouri River at Decatur, NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>4.847182</td>\n",
       "      <td>SUSQUEHANNA RIVER AT CONOWINGO, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>4.750100</td>\n",
       "      <td>Susquehanna River at Marietta, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3.461525</td>\n",
       "      <td>TOMBIGBEE R AT COFFEEVILLE L&amp;D NR COFFEEVILLE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>3.373229</td>\n",
       "      <td>WILLAMETTE RIVER AT PORTLAND, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2.801779</td>\n",
       "      <td>SNAKE RIVER NEAR ANATONE, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.667782</td>\n",
       "      <td>ALABAMA RIVER AT CLAIBORNE L&amp;D NEAR MONROEVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2.632442</td>\n",
       "      <td>SACRAMENTO R A FREEPORT CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2.579267</td>\n",
       "      <td>MISSISSIPPI RIVER AT WINONA, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>2.514199</td>\n",
       "      <td>APALACHICOLA RIVER AT CHATTAHOOCHEE FLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>2.435605</td>\n",
       "      <td>PEND OREILLE RIVER AT INTERNATIONAL BOUNDARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>2.308209</td>\n",
       "      <td>APALACHICOLA RIVER NR SUMATRA,FLA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>2.293901</td>\n",
       "      <td>WILLAMETTE RIVER AT SALEM, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2.273490</td>\n",
       "      <td>PEND OREILLE RIVER AT NEWPORT WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2.240628</td>\n",
       "      <td>KLAMATH R NR KLAMATH CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>2.220437</td>\n",
       "      <td>PEND OREILLE RIVER BELOW BOX CANYON NEAR IONE, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2.211587</td>\n",
       "      <td>Red River at Index, AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>2.183813</td>\n",
       "      <td>Brazos Rv nr Rosharon, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>2.159788</td>\n",
       "      <td>Susquehanna River at Wilkes-Barre, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>2.139836</td>\n",
       "      <td>Brazos Rv at Richmond, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2.095934</td>\n",
       "      <td>POTOMAC RIVER NEAR WASH, DC LITTLE FALLS PUMP STA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2.064639</td>\n",
       "      <td>MISSISSIPPI RIVER AT PRESCOTT, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.052730</td>\n",
       "      <td>White River at DeValls Bluff, AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2.003322</td>\n",
       "      <td>Clark Fork near Plains MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>1.889939</td>\n",
       "      <td>ALTAMAHA RIVER AT DOCTORTOWN, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.881519</td>\n",
       "      <td>SAN JOAQUIN R NR VERNALIS CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.847741</td>\n",
       "      <td>SACRAMENTO R AB BEND BRIDGE NR RED BLUFF CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>1.799783</td>\n",
       "      <td>Trinity Rv at Romayor, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1.797112</td>\n",
       "      <td>ALTAMAHA RIVER NEAR BAXLEY, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1.779757</td>\n",
       "      <td>MISSISSIPPI RIVER AT ST. PAUL, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1.755173</td>\n",
       "      <td>SACRAMENTO R A VERONA CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.659191</td>\n",
       "      <td>SAVANNAH RIVER NEAR CLYO, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.607686</td>\n",
       "      <td>BLACK WARRIOR RIVER AT NORTHPORT AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.605883</td>\n",
       "      <td>POTOMAC RIVER AT POINT OF ROCKS, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1.594011</td>\n",
       "      <td>SALMON RIVER AT WHITE BIRD ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.542279</td>\n",
       "      <td>BLACK WARRIOR RIVER AT SELDEN L &amp; D NEAR EUTAW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.514082</td>\n",
       "      <td>White River at Newport, AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1.470620</td>\n",
       "      <td>PASCAGOULA RIVER AT MERRILL, MS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      annual_hmf                                         station_nm\n",
       "3084    8.263256                   COLUMBIA RIVER AT THE DALLES, OR\n",
       "1461    5.576072                   Missouri River at Sioux City, IA\n",
       "1462    5.218621                      Missouri River at Decatur, NE\n",
       "1691    4.847182                 SUSQUEHANNA RIVER AT CONOWINGO, MD\n",
       "1689    4.750100                  Susquehanna River at Marietta, PA\n",
       "59      3.461525  TOMBIGBEE R AT COFFEEVILLE L&D NR COFFEEVILLE,...\n",
       "3144    3.373229                   WILLAMETTE RIVER AT PORTLAND, OR\n",
       "1125    2.801779                       SNAKE RIVER NEAR ANATONE, WA\n",
       "34      2.667782    ALABAMA RIVER AT CLAIBORNE L&D NEAR MONROEVILLE\n",
       "432     2.632442                         SACRAMENTO R A FREEPORT CA\n",
       "1991    2.579267                    MISSISSIPPI RIVER AT WINONA, MN\n",
       "868     2.514199            APALACHICOLA RIVER AT CHATTAHOOCHEE FLA\n",
       "4037    2.435605       PEND OREILLE RIVER AT INTERNATIONAL BOUNDARY\n",
       "871     2.308209                 APALACHICOLA RIVER NR SUMATRA,FLA.\n",
       "3133    2.293901                      WILLAMETTE RIVER AT SALEM, OR\n",
       "989     2.273490                   PEND OREILLE RIVER AT NEWPORT WA\n",
       "475     2.240628                            KLAMATH R NR KLAMATH CA\n",
       "4036    2.220437  PEND OREILLE RIVER BELOW BOX CANYON NEAR IONE, WA\n",
       "209     2.211587                             Red River at Index, AR\n",
       "3623    2.183813                          Brazos Rv nr Rosharon, TX\n",
       "3245    2.159788              Susquehanna River at Wilkes-Barre, PA\n",
       "3621    2.139836                          Brazos Rv at Richmond, TX\n",
       "1733    2.095934  POTOMAC RIVER NEAR WASH, DC LITTLE FALLS PUMP STA\n",
       "1997    2.064639                  MISSISSIPPI RIVER AT PRESCOTT, WI\n",
       "197     2.052730                   White River at DeValls Bluff, AR\n",
       "2212    2.003322                          Clark Fork near Plains MT\n",
       "912     1.889939                   ALTAMAHA RIVER AT DOCTORTOWN, GA\n",
       "405     1.881519                       SAN JOAQUIN R NR VERNALIS CA\n",
       "417     1.847741        SACRAMENTO R AB BEND BRIDGE NR RED BLUFF CA\n",
       "3561    1.799783                          Trinity Rv at Romayor, TX\n",
       "910     1.797112                     ALTAMAHA RIVER NEAR BAXLEY, GA\n",
       "1984    1.779757                  MISSISSIPPI RIVER AT ST. PAUL, MN\n",
       "429     1.755173                           SACRAMENTO R A VERONA CA\n",
       "886     1.659191                       SAVANNAH RIVER NEAR CLYO, GA\n",
       "54      1.607686                BLACK WARRIOR RIVER AT NORTHPORT AL\n",
       "1727    1.605883                POTOMAC RIVER AT POINT OF ROCKS, MD\n",
       "1092    1.594011                      SALMON RIVER AT WHITE BIRD ID\n",
       "56      1.542279  BLACK WARRIOR RIVER AT SELDEN L & D NEAR EUTAW...\n",
       "196     1.514082                         White River at Newport, AR\n",
       "2021    1.470620                    PASCAGOULA RIVER AT MERRILL, MS"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "metric = 'annual_hmf'\n",
    "df = dfs_valid[f'{date_range}_{percentile}']\n",
    "df = df.dropna(subset='within_aq')\n",
    "df = df.sort_values(by=[metric], ascending=False)\n",
    "df[[metric, 'station_nm']][0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0104b1-f9ef-4598-a22e-fb1a5f023d64",
   "metadata": {},
   "source": [
    "## Sort by OUTLET GAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "193e6b24-4b5c-4de8-a22c-80ef341029ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outlet gages by aquifer\n",
    "br_outlet_gages = ['09520500', '09429600', '09521100', '09519800', '09468500', '09423000', '10327500', '10351650', '10351650', '10311400']\n",
    "cc_outlet_gages = ['11023000', '11046000', '11078000', '11087020', '11133000', '11140000', '11152500', '11159000', '11467000', '11477000', '11530500', '11532500']\n",
    "cv_outlet_gages = ['11303500', '11447650']\n",
    "cl_outlet_gages = ['08211000', '08188500', '08176500', '08164000', '08162000', '08116650', '08066500', '08033500', '08068000', '08030500',\n",
    "      '08013500', '08012000', '07378500', '02492000', '02489500', '02479000', '02479300', '02469761', '02428400', '02375500']\n",
    "fl_outlet_gages = ['02368000', '02365500', '02358000', '02320500', '02313230']\n",
    "hp_outlet_gages = ['06465500', '06805500', '06853500', '06884000', '07144550', '07158000', '07237500', '07228000', '07297910', '08123850']\n",
    "mr_outlet_gages = ['07077000', '07077555', '07047942', '07369000', '07369000', '07285500', '07268000']\n",
    "na_outlet_gages = ['02105769', '02089500', '02091500', '02083500',  '02085000', '02052000', '02047000', '02049500',  '02041650', '02037500', '01668000', \n",
    "      '01673000',  '01646500', '01578310', '01474500',  '01463500']\n",
    "pn_outlet_gages = ['11039800', '12200500', '12040500', '14211720',  '14372300']\n",
    "sr_outlet_gages = ['13269000']\n",
    "cp_outlet_gages = ['13342500', '13334300', '12472800', '12510500', '13351000', '14033500', '14048000', '14103000']\n",
    "rg_outlet_gages = ['08319000']\n",
    "me_outlet_gages = ['07029500', '07268000', '07283000', '07285500', '07289350', '02482550', '02477000', '02469761', '02428400', \n",
    "                   '07362000', '07363500', '07348700']\n",
    "co_outlet_gages = ['05378500', '05407000', '05437500', '04082400']\n",
    "sc_outlet_gages = ['02130561', '02171500', '02197000', '02223248', '02343801', '02467000']\n",
    "bi_outlet_gages = ['02287497', '02289060', '02290765', '02290769']\n",
    "et_outlet_gages = ['07337000', '08062700', '08159200', '08168500']\n",
    "rm_outlet_gages = ['12389000', '06066500', '13302500']\n",
    "pb_outlet_gages = ['02341475', '02339500', '02347500', '02213000', '02223000', '02197000', '02169500', \n",
    "'02148000', '02130561', '02102500', '02089000', '02083500' ,'02080500', '01646500', '01578310']\n",
    "sa_outlet_gages = ['02359170', '02243960', '02296750', '02292900', '02226000', '02202500', '02198500', '02175000', '02171645']\n",
    "vr_outlet_gages = ['02388500', '02397000', '03513000', '03455000', '03168000', '02019500', '01638500', '01570500']\n",
    "sd_outlet_gages = ['05465500', '05420500', '05527500', '03335500']\n",
    "pnb_outlet_gages = ['13087995', '12395500']\n",
    "wl_outlet_gages = ['14211720']\n",
    "lc_outlet_gages = ['05476750', '05479000', '05482300', '05483450', '06602020', '06606600', '06607200',\n",
    "       '06809210', '06486000', '06601200', '06864500', '06865500', '06868200', '06869500',\n",
    "       '06876700', '06884025', '06884200', '05061500', '05304500', '05313500', '05317000',\n",
    "       '05476000', '06078200', '06090300', '06200000', '06601000', '06803000', '06803500',\n",
    "       '06803510', '06803530', '06804000', '06881000', '05085000', '06395000', '06400000',\n",
    "       '06402500', '06406000', '06414000', '06430500', '06433000', '06436000', '06436190',\n",
    "       '06429997', '06279500', '06634620']\n",
    "\n",
    "outlet_gages_dict_10 = {\n",
    "    'br': br_outlet_gages, \n",
    "    'cc': cc_outlet_gages,\n",
    "    'cv': cv_outlet_gages,\n",
    "    'cl': cl_outlet_gages,\n",
    "    'fl': fl_outlet_gages,\n",
    "    'hp': hp_outlet_gages,\n",
    "    'mr': mr_outlet_gages,\n",
    "    'na': na_outlet_gages,\n",
    "    'pn': pn_outlet_gages,\n",
    "    'sr': sr_outlet_gages\n",
    "}\n",
    "\n",
    "outlet_gages_dict_25 = {\n",
    "    'br': br_outlet_gages, \n",
    "    'cc': cc_outlet_gages,\n",
    "    'cv': cv_outlet_gages,\n",
    "    'cl': cl_outlet_gages,\n",
    "    'fl': fl_outlet_gages,\n",
    "    'hp': hp_outlet_gages,\n",
    "    'mr': mr_outlet_gages,\n",
    "    'na': na_outlet_gages,\n",
    "    'pn': pn_outlet_gages,\n",
    "    'sr': sr_outlet_gages,\n",
    "    'cp': cp_outlet_gages,\n",
    "    'rg': rg_outlet_gages,\n",
    "    'me': me_outlet_gages,\n",
    "    'co': co_outlet_gages,\n",
    "    'sc': sc_outlet_gages,\n",
    "    'bi': bi_outlet_gages,\n",
    "    'et': et_outlet_gages,\n",
    "    'rm': rm_outlet_gages,\n",
    "    'pb': pb_outlet_gages,\n",
    "    'sa': sa_outlet_gages,\n",
    "    'vr': vr_outlet_gages,\n",
    "    'sd': sd_outlet_gages,\n",
    "    'pnb': pnb_outlet_gages,\n",
    "    'wl': wl_outlet_gages,\n",
    "    'lc': lc_outlet_gages}\n",
    "\n",
    "aq_names_10 = {'hp': 'High Plains aquifer',\n",
    "                'mr': 'Mississippi River Valley alluvial aquifer',\n",
    "                'cv': 'Central Valley aquifer system',\n",
    "                'br': 'Basin and Range basin-fill aquifers',\n",
    "                'fl': 'Floridan aquifer system',\n",
    "                'sr': 'Snake River Plain basaltic-rock aquifers',\n",
    "                'cl': 'Coastal lowlands aquifer system',\n",
    "                'cc': 'California Coastal Basin aquifers', \n",
    "                'pn': 'Pacific Northwest basin-fill aquifers',\n",
    "                'na': 'Northern Atlantic Coastal Plain aquifer system'}\n",
    "\n",
    "aq_names_25 = {'hp': 'High Plains aquifer',\n",
    "                'mr': 'Mississippi River Valley alluvial aquifer',\n",
    "                'cv': 'Central Valley aquifer system',\n",
    "                'br': 'Basin and Range basin-fill aquifers',\n",
    "                'fl': 'Floridan aquifer system',\n",
    "                'sr': 'Snake River Plain basaltic-rock aquifers',\n",
    "                'cl': 'Coastal lowlands aquifer system',\n",
    "                'cc': 'California Coastal Basin aquifers', \n",
    "                'pn': 'Pacific Northwest basin-fill aquifers',\n",
    "                'na': 'Northern Atlantic Coastal Plain aquifer system',\n",
    "                'cp': 'Columbia Plateau basaltic-rock aquifers',\n",
    "                'rg': 'Rio Grande aquifer system',\n",
    "                'me': 'Mississippi embayment aquifer system',\n",
    "                'co': 'Cambrian-Ordovician aquifer system',\n",
    "                'sc': 'Southeastern Coastal Plain aquifer system',\n",
    "                'bi': 'Biscayne aquifer',\n",
    "                'et': 'Edwards-Trinity aquifer system',\n",
    "                'rm': 'Northern Rocky Mountains Intermontane Basins aquifer system',\n",
    "                'pb': 'Piedmont and Blue Ridge crystalline-rock aquifers',\n",
    "                'sa': 'Surficial aquifer system',\n",
    "                'vr': 'Valley and Ridge aquifers',\n",
    "                'sd': 'Silurian-Devonian aquifers',\n",
    "                'pnb': 'Pacific Northwest basaltic-rock aquifers',\n",
    "                'wl': 'Willamette Lowland basin-fill aquifers',\n",
    "                'lc': 'Lower Cretaceous aquifers'\n",
    "              }\n",
    "\n",
    "aq_codes_10 = ['hp', 'mr', 'cv', 'br', 'fl', 'sr', 'cl', 'cc', 'pn', 'na']\n",
    "\n",
    "aq_codes_25 = ['hp', 'mr', 'cv', 'br', 'fl', 'sr', 'cl', 'cc', 'pn', 'na',\n",
    "              'cp', 'rg', 'me', 'co', 'sc', 'bi', 'et', 'rm', 'pb', 'sa',\n",
    "              'vr', 'sd', 'pnb', 'wl', 'lc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "103725a5-2e2e-415f-9fe7-8aab178a8755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_outlet_gages = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles: \n",
    "        df_outlet_gages_aq = {}\n",
    "        df_temp = dfs_valid[f'{date_range}_{percentile}']\n",
    "\n",
    "        for key, value in outlet_gages_dict_25.items():\n",
    "            df_outlet_gages_aq[key] = df_temp[df_temp['site_no'].isin(value)].copy()\n",
    "            #print(df_outlet_gages_aq)\n",
    "            # Add the key as a column to each DataFrame\n",
    "            df_outlet_gages_aq[key].loc[:, 'aq'] = aq_names_25[key]\n",
    "\n",
    "            #print(df_outlet_gages_aq)\n",
    "       \n",
    "        df_outlet_gages[f'{date_range}_{percentile}'] = df_outlet_gages_aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96bccf-a44d-475d-af5a-5a3d1fc7a256",
   "metadata": {},
   "source": [
    "### Tables for mean HMF metrics at aquifer OUTLET gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7c74ccee-2c5e-4336-9b92-e68f10b4871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean HMF metrics: OUTLET GAGES (by aquifer)\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'aq']\n",
    "\n",
    "df_mean_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df = pd.concat(df_outlet_gages[f'{date_range}_{percentile}'].values(), ignore_index=True)\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'] = df[metric_list].groupby('aq').mean()\n",
    "        df_mean_metrics[f'{date_range}_{percentile}']['type'] = 'mean'\n",
    "\n",
    "# OLD CODE\n",
    "# metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "#                'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "#               'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "#                'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf']\n",
    "#\n",
    "#         data = {metric: [] for metric in metric_list}\n",
    "        \n",
    "#         # Loop through each aq code and metric to calculate the average and store in the dictionary\n",
    "#         for aq in aq_codes_25:\n",
    "#             for metric in metric_list:\n",
    "#                 avg = df_outlet_gages[f'{date_range}_{percentile}'][aq][metric].mean()\n",
    "#                 data[metric].append(avg)\n",
    "        \n",
    "#         # Convert the dictionary to a DataFrame\n",
    "#         df_mean_metrics[f'{date_range}_{percentile}'] = pd.DataFrame(data, index=list(aq_names_25.values())) # index can also =aq_codes_25\n",
    "#         df_mean_metrics[f'{date_range}_{percentile}']['type'] = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5d47bba8-855d-4250-a0ca-2f200ce747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_outlet_mean_{date_range}_{percentile}.xlsx'\n",
    "        df_mean_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea88821-9ac4-460e-9772-e902f8b3c522",
   "metadata": {},
   "source": [
    "### Tables for min HMF metrics at aquifer OUTLET gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a90e7e4a-d428-4f5d-8579-1b21c5cbd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min HMF metrics: OUTLET GAGES (by aquifer)\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'aq']\n",
    "\n",
    "df_min_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df = pd.concat(df_outlet_gages[f'{date_range}_{percentile}'].values(), ignore_index=True)\n",
    "        df_min_metrics[f'{date_range}_{percentile}'] = df[metric_list].groupby('aq').min()\n",
    "        df_min_metrics[f'{date_range}_{percentile}']['type'] = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce5e7b53-78ad-402c-907f-e8c1cf8f9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_outlet_min_{date_range}_{percentile}.xlsx'\n",
    "        df_min_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a1662-927f-4ee8-9542-3bdc36dee331",
   "metadata": {},
   "source": [
    "### Tables for max HMF metrics at aquifer OUTLET gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "24a954bb-09ba-4d5e-ae58-768e6bbedf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max HMF metrics: OUTLET GAGES (by aquifer)\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing',\n",
    "              'jan_hmf', 'feb_hmf', 'mar_hmf', 'apr_hmf', 'may_hmf', 'jun_hmf', 'jul_hmf',\n",
    "               'aug_hmf', 'sep_hmf', 'oct_hmf', 'nov_hmf', 'dec_hmf', 'aq']\n",
    "\n",
    "df_max_metrics = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df = pd.concat(df_outlet_gages[f'{date_range}_{percentile}'].values(), ignore_index=True)\n",
    "        df_max_metrics[f'{date_range}_{percentile}'] = df[metric_list].groupby('aq').max()\n",
    "        df_max_metrics[f'{date_range}_{percentile}']['type'] = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "41b1b01e-a918-4006-931c-61f9b093d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_hmf_metrics_outlet_max_{date_range}_{percentile}.xlsx'\n",
    "        df_max_metrics[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8dc2e8-2b6c-453b-9e24-2b953bd4d008",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combine max, mean, and min tables and save as one excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4cb5b348-b862-4967-a0f9-258fb1c9ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        # Combine the three dataframes\n",
    "        df_combined = pd.concat([df_min_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_mean_metrics[f'{date_range}_{percentile}'], \n",
    "                                 df_max_metrics[f'{date_range}_{percentile}']])\n",
    "\n",
    "        # Sort the combined dataframe to ensure the order is min, mean, max for each aquifer\n",
    "        df_combined = df_combined.sort_values(by=['aq', 'type'])\n",
    "\n",
    "        # Save the combined dataframe to a new Excel file\n",
    "        file_name = f'aq_hmf_metrics_outlet_{date_range}_{percentile}.xlsx'\n",
    "        df_combined.to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84be1a5-3a64-4558-85aa-9b333e5f5c2b",
   "metadata": {},
   "source": [
    "### Tables for sum of annual HMF at aquifer OUTLET gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32bae831-92cf-4978-9983-6eb5bb191eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of annual HMF: OUTLET gages (by aquifer)\n",
    "metric = 'annual_hmf'\n",
    "df_sum_annual_hmf = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "\n",
    "        # Loop through each aq code to calculate the sum of the annual_hmf\n",
    "        sum_list = []\n",
    "        for aq in aq_codes_25:\n",
    "            sums = df_outlet_gages[f'{date_range}_{percentile}'][aq][metric].sum()\n",
    "            sum_list.append(sums)\n",
    "            \n",
    "        df_sum_annual_hmf[f'{date_range}_{percentile}'] = pd.DataFrame(sum_list, list(aq_names_25.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e852a0c2-da8a-4b13-a185-a752779d431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to excel\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'aq_annual_hmf_sum_outlet_{date_range}_{percentile}.xlsx'\n",
    "        df_sum_annual_hmf[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84599f-7811-49a3-935f-fea7135ffafa",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85282440-f077-4d13-a8a4-bea829a30179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = 'timing'\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing']\n",
    "aq_colors = ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'cyan', 'magenta', 'lime', 'pink']\n",
    "alpha_list = [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "date_range = '30'\n",
    "percentile = '90'\n",
    "\n",
    "def outlet_gages_metrics_boxplot(metric, date_range, percentile):\n",
    "    fig, ax = plt.subplots(figsize=(18, 6))\n",
    "    # plt.boxplot([df_outlet_gages[f'{date_range}_{percentile}']['hp'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['mr'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['cv'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['br'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['fl'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['sr'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['cl'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['cc'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['pn'][metric],\n",
    "    #              df_outlet_gages[f'{date_range}_{percentile}']['na'][metric]\n",
    "    #             ])\n",
    "\n",
    "    for j, aq_code in enumerate(aq_codes):\n",
    "        ax.boxplot(df_outlet_gages[f'{date_range}_{percentile}'][aq_code][metric], positions=[j], widths=0.6, patch_artist=True,\n",
    "                boxprops=dict(facecolor=aq_colors[j], alpha=alpha_list[j]), \n",
    "                medianprops=dict(color='#000000'),\n",
    "                showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n",
    "\n",
    "    tick_labels = ['High Plains',\n",
    "                    'Mississippi \\n River Valley',\n",
    "                    'Central Valley ',\n",
    "                    'Basin and \\n Range',\n",
    "                    'Floridan',\n",
    "                    'Snake River \\n Plain',\n",
    "                    'Coastal \\n Lowlands',\n",
    "                    'California \\n Coastal Basin ', \n",
    "                    'Pacific \\n Northwest ',\n",
    "                    'Northern Atlantic \\n Coastal Plain']\n",
    "\n",
    "    plt.xticks([0,1,2,3,4,5,6,7,8,9], tick_labels, fontsize=14)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=18)\n",
    "    plt.ylabel(f'{fn.FLOW_METRIC_UNITS[metric]}', fontsize=20)\n",
    "    plt.title(f'{fn.FLOW_METRIC_UNITS[metric]} ({date_range}-Year Record, {percentile}th Percentile)', fontsize=24)\n",
    "\n",
    "    plt.savefig(f'Saved_Visuals/Aquifers/HMF_metrics/boxplots_{metric}_{date_range}_{percentile}.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "              \n",
    "# for date_range in date_ranges:\n",
    "#     for percentile in percentiles:\n",
    "#         for metric in metric_list:\n",
    "#               outlet_gages_metrics_boxplot(metric, date_range, percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a141a8-56ec-4582-bdb3-53195d805978",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sort by HUC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64152067-c68c-43d3-a0c5-ee3ac0a6f8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp = dfs_valid['30_90']\n",
    "huc2_codes = dfs_valid['30_90']['huc2_code'].unique().tolist()\n",
    "#huc2_codes\n",
    "dict_huc2 = {}\n",
    "for huc2_code in huc2_codes:\n",
    "    dict_huc2[huc2_code] = df_temp[df_temp['huc2_code'] == huc2_code]['site_no'].unique().tolist()\n",
    "#dict_huc2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad023041-d80d-4ddd-95e8-cbfb8e1d2557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_huc2_gages = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles: \n",
    "        df_huc2_huc = {}\n",
    "        df_temp = dfs_valid[f'{date_range}_{percentile}']\n",
    "\n",
    "        for key, value in dict_huc2.items():\n",
    "            df_huc2_huc[key] = df_temp[df_temp['site_no'].isin(value)]\n",
    "       \n",
    "        df_huc2_gages[f'{date_range}_{percentile}'] = df_huc2_huc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba32742-6001-4a1b-821c-aba065478f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huc2_codes = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "colors = ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'cyan', 'magenta', 'lime', 'pink',\n",
    "               'teal', 'lavender', 'brown', 'black', 'maroon', 'lightblue', 'coral', 'olive']\n",
    "metric_list = ['annual_hmf', 'annual_duration', 'event_duration',\n",
    "               'event_hmf', 'inter_annual%', 'intra_annual', 'timing']\n",
    "\n",
    "def huc2_gages_metrics_boxplot(metric, date_range, percentile):\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    # plt.boxplot([df_huc2_gages[f'{date_range}_{percentile}'][1][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][2][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][3][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][4][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][5][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][6][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][7][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][8][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][9][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][10][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][11][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][12][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][13][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][14][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][15][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][16][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][17][metric],\n",
    "    #              df_huc2_gages[f'{date_range}_{percentile}'][18][metric]\n",
    "    #             ])\n",
    "\n",
    "    for j, code in enumerate(huc2_codes):\n",
    "        ax.boxplot(df_huc2_gages[f'{date_range}_{percentile}'][code][metric], positions=[j], widths=0.6, patch_artist=True,\n",
    "                boxprops=dict(facecolor=colors[j]), #alpha=alpha_list[j]), \n",
    "                medianprops=dict(color='#000000'),\n",
    "                showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n",
    "\n",
    "    tick_labels = ['HUC1', 'HUC2', 'HUC3', 'HUC4', 'HUC5', 'HUC6', 'HUC7', 'HUC8', 'HUC9',\n",
    "                   'HUC10', 'HUC11', 'HUC12', 'HUC13', 'HUC14', 'HUC15', 'HUC16', 'HUC17', 'HUC18']\n",
    "\n",
    "    plt.xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17], tick_labels, fontsize=14)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=18)\n",
    "    plt.ylabel(f'{fn.FLOW_METRIC_UNITS[metric]}', fontsize=20)\n",
    "    plt.title(f'{fn.FLOW_METRIC_UNITS[metric]} ({date_range}-Year Record, {percentile}th Percentile)', fontsize=24)\n",
    "\n",
    "    plt.savefig(f'Saved_Visuals/HUC2/HMF_metrics/boxplots_{metric}_{date_range}_{percentile}.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "# for date_range in date_ranges:\n",
    "#     for percentile in percentiles:\n",
    "#         for metric in metric_list:\n",
    "#               huc2_gages_metrics_boxplot(metric, date_range, percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2767f37-7010-4825-9fe2-fc1cfba1aac3",
   "metadata": {},
   "source": [
    "## Count valid gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15573b8b-7dfb-4113-bc74-9670f4cbe2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_range</th>\n",
       "      <th>all_gages</th>\n",
       "      <th>valid_gages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>7914</td>\n",
       "      <td>4242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>7914</td>\n",
       "      <td>3314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_range  all_gages  valid_gages\n",
       "0         30       7914         4242\n",
       "1         50       7914         3314"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gages_count = pd.DataFrame()\n",
    "all_30 = len(dfs_metrics['30_90'])\n",
    "all_50 = len(dfs_metrics['50_90'])\n",
    "valid_30 = len(dfs_valid['30_90'][dfs_valid['30_90']['valid'] == True])\n",
    "valid_50 = len(dfs_valid['50_90'][dfs_valid['50_90']['valid'] == True])\n",
    "df_gages_count['data_range'] = ['30', '50']\n",
    "df_gages_count['all_gages'] = [all_30, all_50]\n",
    "df_gages_count['valid_gages'] = [valid_30, valid_50]\n",
    "df_gages_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c632a5bd-4eac-481d-83cd-be04c640b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "df_aq_count_30_90 = pd.DataFrame()\n",
    "\n",
    "num_gages_aq = []\n",
    "num_gages_aq_outlet = []\n",
    "for aq in aq_codes:\n",
    "    num_gages_aq.append(len(dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'] == aq_names_10[aq]]))\n",
    "    num_gages_aq_outlet.append(len(df_outlet_gages[f'{date_range}_{percentile}'][aq]))\n",
    "\n",
    "df_aq_count_30_90['aq'] = aq_names_10.keys()    \n",
    "df_aq_count_30_90['valid_all'] = num_gages_aq\n",
    "df_aq_count_30_90['valid_outlet'] = num_gages_aq_outlet\n",
    "\n",
    "date_range = '50'\n",
    "percentile = '90'\n",
    "df_aq_count_50_90 = pd.DataFrame()\n",
    "\n",
    "num_gages_aq = []\n",
    "num_gages_aq_outlet = []\n",
    "for aq in aq_codes:\n",
    "    num_gages_aq.append(len(dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'] == aq_names_10[aq]]))\n",
    "    num_gages_aq_outlet.append(len(df_outlet_gages[f'{date_range}_{percentile}'][aq]))\n",
    "\n",
    "df_aq_count_50_90['aq'] = aq_names_10.keys()    \n",
    "df_aq_count_50_90['valid_all'] = num_gages_aq\n",
    "df_aq_count_50_90['valid_outlet'] = num_gages_aq_outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5f78184-98fa-4213-89c5-69b13d3505ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aq  valid_all  valid_outlet\n",
      "0  hp         71            11\n",
      "1  mr         15             6\n",
      "2  cv         20             2\n",
      "3  br        134             9\n",
      "4  fl         47             5\n",
      "5  sr          9             1\n",
      "6  cl        106            20\n",
      "7  cc         65            12\n",
      "8  pn         65             4\n",
      "9  na         92            16\n",
      "   aq  valid_all  valid_outlet\n",
      "0  hp         63            11\n",
      "1  mr         11             3\n",
      "2  cv         17             2\n",
      "3  br         90             7\n",
      "4  fl         34             5\n",
      "5  sr          6             1\n",
      "6  cl         90            20\n",
      "7  cc         55            11\n",
      "8  pn         52             4\n",
      "9  na         72            15\n"
     ]
    }
   ],
   "source": [
    "print(df_aq_count_30_90)\n",
    "print(df_aq_count_50_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6295416d-166c-497d-a6d8-0cd613ff7a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "df_huc2_count_30_90 = pd.DataFrame()\n",
    "\n",
    "num_gages_huc2 = []\n",
    "for huc2 in huc2_codes:\n",
    "    num_gages_huc2.append(len(dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['huc2_code'] == huc2]))\n",
    "\n",
    "df_huc2_count_30_90['huc2'] = huc2_codes   \n",
    "df_huc2_count_30_90['valid_all'] = num_gages_huc2\n",
    "\n",
    "date_range = '50'\n",
    "percentile = '90'\n",
    "df_huc2_count_50_90 = pd.DataFrame()\n",
    "\n",
    "num_gages_huc2 = []\n",
    "for huc2 in huc2_codes:\n",
    "    num_gages_huc2.append(len(dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['huc2_code'] == huc2]))\n",
    "\n",
    "df_huc2_count_50_90['huc2'] = huc2_codes      \n",
    "df_huc2_count_50_90['valid_all'] = num_gages_huc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533debe6-3352-4cae-8dce-3c21be73d742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    huc2  valid_all\n",
      "0      1        164\n",
      "1      2        440\n",
      "2      3        549\n",
      "3      4        234\n",
      "4      5        324\n",
      "5      6         47\n",
      "6      7        319\n",
      "7      8         49\n",
      "8      9         60\n",
      "9     10        399\n",
      "10    11        259\n",
      "11    12        211\n",
      "12    13         71\n",
      "13    14        159\n",
      "14    15        147\n",
      "15    16        127\n",
      "16    17        446\n",
      "17    18        237\n",
      "    huc2  valid_all\n",
      "0      1        144\n",
      "1      2        360\n",
      "2      3        361\n",
      "3      4        184\n",
      "4      5        289\n",
      "5      6         38\n",
      "6      7        255\n",
      "7      8         46\n",
      "8      9         53\n",
      "9     10        312\n",
      "10    11        197\n",
      "11    12        177\n",
      "12    13         61\n",
      "13    14        119\n",
      "14    15         99\n",
      "15    16         90\n",
      "16    17        328\n",
      "17    18        201\n",
      "huc2          171\n",
      "valid_all    4242\n",
      "dtype: int64\n",
      "huc2          171\n",
      "valid_all    3314\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_huc2_count_30_90)\n",
    "print(df_huc2_count_50_90)\n",
    "print(df_huc2_count_30_90.sum())\n",
    "print(df_huc2_count_50_90.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f448046-372c-4728-a2fd-3ff4ad1c11c0",
   "metadata": {},
   "source": [
    "## Import annual subdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f39a770-5c92-4d62-a781-5bd4a0a7ae29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subdfs_metrics_30_90 = pd.read_parquet(f'Prelim_Data/annual_metrics_subdf_30_90.parquet', engine='pyarrow') # only includes valid gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fe035e3-7f10-475a-baac-d8ca2af60880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>water_year</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01010000</th>\n",
       "      <td>0.748652</td>\n",
       "      <td>0.441949</td>\n",
       "      <td>0.430720</td>\n",
       "      <td>0.765338</td>\n",
       "      <td>0.251239</td>\n",
       "      <td>0.660845</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>0.186796</td>\n",
       "      <td>0.557501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004075</td>\n",
       "      <td>3.246850e-01</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>0.568486</td>\n",
       "      <td>0.400088</td>\n",
       "      <td>0.225648</td>\n",
       "      <td>0.730817</td>\n",
       "      <td>0.920353</td>\n",
       "      <td>0.893979</td>\n",
       "      <td>0.601931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01010070</th>\n",
       "      <td>0.089350</td>\n",
       "      <td>0.077409</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.032152</td>\n",
       "      <td>0.097750</td>\n",
       "      <td>0.106775</td>\n",
       "      <td>0.076489</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.072326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121326</td>\n",
       "      <td>6.393195e-02</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.091186</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.113423</td>\n",
       "      <td>0.108348</td>\n",
       "      <td>0.066785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01010500</th>\n",
       "      <td>1.490209</td>\n",
       "      <td>0.869758</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>1.477976</td>\n",
       "      <td>0.524301</td>\n",
       "      <td>1.457425</td>\n",
       "      <td>1.489475</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>0.433044</td>\n",
       "      <td>1.055942</td>\n",
       "      <td>...</td>\n",
       "      <td>1.864046</td>\n",
       "      <td>6.882217e-01</td>\n",
       "      <td>0.851408</td>\n",
       "      <td>1.251913</td>\n",
       "      <td>0.773852</td>\n",
       "      <td>0.624366</td>\n",
       "      <td>1.775969</td>\n",
       "      <td>1.690094</td>\n",
       "      <td>1.781596</td>\n",
       "      <td>1.159187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01011000</th>\n",
       "      <td>0.617682</td>\n",
       "      <td>0.242206</td>\n",
       "      <td>0.249509</td>\n",
       "      <td>0.535658</td>\n",
       "      <td>0.106394</td>\n",
       "      <td>0.427794</td>\n",
       "      <td>0.537750</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>0.510955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601466</td>\n",
       "      <td>2.112178e-01</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>0.416512</td>\n",
       "      <td>0.248658</td>\n",
       "      <td>0.178030</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>0.522483</td>\n",
       "      <td>0.379469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01013500</th>\n",
       "      <td>0.365078</td>\n",
       "      <td>0.131626</td>\n",
       "      <td>0.126830</td>\n",
       "      <td>0.250064</td>\n",
       "      <td>0.111735</td>\n",
       "      <td>0.260340</td>\n",
       "      <td>0.352233</td>\n",
       "      <td>0.253025</td>\n",
       "      <td>0.089985</td>\n",
       "      <td>0.295595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>6.850412e-02</td>\n",
       "      <td>0.107429</td>\n",
       "      <td>0.238884</td>\n",
       "      <td>0.090450</td>\n",
       "      <td>0.112958</td>\n",
       "      <td>0.410095</td>\n",
       "      <td>0.428346</td>\n",
       "      <td>0.394535</td>\n",
       "      <td>0.170331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265501080364900</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.026599</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393109104464500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>7.821702e-04</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394839104570300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>4.181198e-03</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401723105400000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401733105392404</th>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>7.339727e-07</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4242 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "water_year           1990      1991      1992      1993      1994      1995  \\\n",
       "site_no                                                                       \n",
       "01010000         0.748652  0.441949  0.430720  0.765338  0.251239  0.660845   \n",
       "01010070         0.089350  0.077409  0.055046  0.109819  0.032152  0.097750   \n",
       "01010500         1.490209  0.869758  0.860705  1.477976  0.524301  1.457425   \n",
       "01011000         0.617682  0.242206  0.249509  0.535658  0.106394  0.427794   \n",
       "01013500         0.365078  0.131626  0.126830  0.250064  0.111735  0.260340   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "265501080364900  0.000000  0.000000  0.001703  0.000000  0.000000  0.001473   \n",
       "393109104464500       NaN  0.002206  0.000607  0.000163  0.002542  0.000146   \n",
       "394839104570300       NaN  0.006014  0.000869  0.001906  0.013830  0.004191   \n",
       "401723105400000  0.000000  0.000053  0.000219  0.000106  0.000414  0.000396   \n",
       "401733105392404  0.000424  0.000028  0.000494  0.000246  0.001003  0.000899   \n",
       "\n",
       "water_year           1996      1997      1998      1999  ...      2010  \\\n",
       "site_no                                                  ...             \n",
       "01010000         0.706228  0.535800  0.186796  0.557501  ...  1.004075   \n",
       "01010070         0.106775  0.076489  0.034719  0.072326  ...  0.121326   \n",
       "01010500         1.489475  0.996246  0.433044  1.055942  ...  1.864046   \n",
       "01011000         0.537750  0.401270  0.150004  0.510955  ...  0.601466   \n",
       "01013500         0.352233  0.253025  0.089985  0.295595  ...  0.274677   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "265501080364900  0.000000  0.000000  0.000000  0.007372  ...  0.000000   \n",
       "393109104464500  0.000516  0.005090  0.008260  0.001128  ...  0.000314   \n",
       "394839104570300  0.034095  0.004876  0.018420  0.004470  ...  0.007535   \n",
       "401723105400000  0.000254  0.000283  0.000307  0.000103  ...  0.000602   \n",
       "401733105392404  0.001172  0.000663  0.000862  0.000602  ...  0.002080   \n",
       "\n",
       "water_year               2011      2012      2013      2014      2015  \\\n",
       "site_no                                                                 \n",
       "01010000         3.246850e-01  0.440261  0.568486  0.400088  0.225648   \n",
       "01010070         6.393195e-02  0.064016  0.091186  0.058018  0.063367   \n",
       "01010500         6.882217e-01  0.851408  1.251913  0.773852  0.624366   \n",
       "01011000         2.112178e-01  0.235003  0.416512  0.248658  0.178030   \n",
       "01013500         6.850412e-02  0.107429  0.238884  0.090450  0.112958   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "265501080364900  0.000000e+00  0.026599  0.010978  0.005808  0.004553   \n",
       "393109104464500  7.821702e-04  0.000653  0.000000  0.003974  0.001431   \n",
       "394839104570300  4.181198e-03  0.024184  0.000000  0.011570  0.004061   \n",
       "401723105400000  0.000000e+00  0.000219  0.000253  0.000333  0.000254   \n",
       "401733105392404  7.339727e-07  0.000883  0.000752  0.001361  0.000744   \n",
       "\n",
       "water_year           2016      2017      2018      2019  \n",
       "site_no                                                  \n",
       "01010000         0.730817  0.920353  0.893979  0.601931  \n",
       "01010070         0.137806  0.113423  0.108348  0.066785  \n",
       "01010500         1.775969  1.690094  1.781596  1.159187  \n",
       "01011000         0.559138  0.577957  0.522483  0.379469  \n",
       "01013500         0.410095  0.428346  0.394535  0.170331  \n",
       "...                   ...       ...       ...       ...  \n",
       "265501080364900  0.002202  0.000000  0.000000  0.000000  \n",
       "393109104464500  0.000822  0.000127  0.001657  0.001510  \n",
       "394839104570300  0.002728  0.002640  0.002048  0.000847  \n",
       "401723105400000  0.000266  0.000029  0.000317  0.000051  \n",
       "401733105392404  0.001164  0.000123  0.001263  0.000296  \n",
       "\n",
       "[4242 rows x 30 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = subdfs_metrics_30_90[['site_no', 'water_year', 'annual_hmf']]\n",
    "pivot_df = test_df.pivot(index='site_no', columns='water_year', values='annual_hmf')\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c259554e-bec3-48ac-b4b2-93c76c8f3a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows = pivot_df[pivot_df.isna().any(axis=1)]\n",
    "len(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6918d67-71ca-444d-9e63-4374acabaf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HMF (30-year, 90th percentile): 23658.686901018093 km3\n"
     ]
    }
   ],
   "source": [
    "# Only \n",
    "len(list(subdfs_metrics_30_90['site_no'].unique()))\n",
    "total_hmf_30_90 = subdfs_metrics_30_90['annual_hmf'].sum()\n",
    "print(f'Total HMF (30-year, 90th percentile): {total_hmf_30_90} km3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478edc20-8e33-44e0-8d45-1af183f196ad",
   "metadata": {},
   "source": [
    "## Sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29806570-989f-4415-b421-d867061b4996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_range = '30'\n",
    "percentile = '90'\n",
    "top_50_annual_hmf = dfs_valid[f'{date_range}_{percentile}'].sort_values(by=['annual_hmf'], ascending=False)[0:50]\n",
    "#top_50_annual_hmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34310a8-96e5-411e-b1cb-7f56e0d699b6",
   "metadata": {},
   "source": [
    "## Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "476ce981-f732-4365-9d4d-beff090eb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057\n",
      "4242\n",
      "48.49127769919849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4242.000000\n",
       "mean        0.209971\n",
       "std         0.682611\n",
       "min         0.000003\n",
       "25%         0.015643\n",
       "50%         0.053223\n",
       "75%         0.162787\n",
       "max        14.069366\n",
       "Name: annual_hmf, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "metric = 'annual_hmf'\n",
    "\n",
    "# CONUS\n",
    "df = dfs_valid[f'{date_range}_{percentile}']\n",
    "\n",
    "# Top 25\n",
    "#df = dfs_aq[f'{date_range}_{percentile}']\n",
    "\n",
    "# Top 10\n",
    "#df = dfs_aq[f'{date_range}_{percentile}']\n",
    "#df = df.loc[df['within_aq'].isin(aq_names_10)]\n",
    "\n",
    "n = 15\n",
    "high_value = 100\n",
    "top_value = df.sort_values(by=[metric], ascending=False)[0:n].reset_index()\n",
    "high_value = df[df[metric] > high_value].reset_index()\n",
    "\n",
    "high_value = 0.15\n",
    "low_value = 0.015\n",
    "mid_annual_value = df[(df[metric] <= high_value) & (df[metric] >= low_value)].reset_index()\n",
    "\n",
    "#low_annual_hmf = \n",
    "\n",
    "print(len(mid_annual_value))\n",
    "print(len(df))\n",
    "print(len(mid_annual_value) / len(df) * 100)\n",
    "#high_annual_hmf\n",
    "\n",
    "df[metric].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a52230b-d1ca-4d6b-b8f6-a68cb074b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "4242\n",
      "0.7543611504007544\n"
     ]
    }
   ],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "metric = 'annual_hmf'\n",
    "n = 164\n",
    "top_annual_hmf = dfs_valid[f'{date_range}_{percentile}'].sort_values(by=[metric], ascending=False)[0:n].reset_index()\n",
    "high_annual_hmf = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['annual_hmf'] > 3.0].reset_index()\n",
    "print(len(high_annual_hmf))\n",
    "print(len(dfs_valid[f'{date_range}_{percentile}']))\n",
    "print(len(high_annual_hmf) / len(dfs_valid[f'{date_range}_{percentile}']) * 100)\n",
    "#high_annual_hmf\n",
    "\n",
    "# Greater than 4 km3 - Missouri R, Ohio R, Susequehana R, Columbia R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45cc114c-45e9-49ea-a763-50530536a91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All valid gages\n",
    "df_gages_boxplot = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_metrics = {}\n",
    "        for metric in metric_list:\n",
    "            temp_df = dfs_valid[f'{date_range}_{percentile}'][metric]\n",
    "            temp_df = temp_df.describe()\n",
    "            df_metrics[metric] = temp_df\n",
    "        df_gages_boxplot[f'{date_range}_{percentile}'] = df_metrics\n",
    "\n",
    "# All valid aquifer gages (25 grouped)\n",
    "df_aq25_grouped_boxplot = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_metrics = {}\n",
    "        for metric in metric_list:\n",
    "            temp_df = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25_list)]\n",
    "            temp_df = temp_df[metric].describe()\n",
    "            df_metrics[metric] = temp_df\n",
    "        df_aq25_grouped_boxplot[f'{date_range}_{percentile}'] = df_metrics\n",
    "\n",
    "# All valid aquifer gages (10 grouped)\n",
    "df_aq10_grouped_boxplot = {}\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_metrics = {}\n",
    "        for metric in metric_list:\n",
    "            temp_df = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_10_list)]\n",
    "            temp_df = temp_df[metric].describe()\n",
    "            df_metrics[metric] = temp_df\n",
    "        df_aq10_grouped_boxplot[f'{date_range}_{percentile}'] = df_metrics\n",
    "            \n",
    "# Valid HUC2 gages\n",
    "df_huc2_boxplot = {}\n",
    "# Loop through date ranges and percentiles\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_huc2 = {}\n",
    "        # Loop through HUC2 codes\n",
    "        for huc2 in huc2_codes:\n",
    "            temp_df = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['huc2_code'] == huc2]\n",
    "            df_metrics = {}\n",
    "            # Loop through metrics\n",
    "            for metric in metric_list:\n",
    "                metrics_desc = temp_df[metric].describe()\n",
    "                #print(metrics_desc)\n",
    "                df_metrics[metric] = metrics_desc\n",
    "            df_huc2[huc2] = df_metrics\n",
    "        df_huc2_boxplot[f'{date_range}_{percentile}'] = df_huc2\n",
    "\n",
    "        \n",
    "# Valid aquifer gages\n",
    "df_aq_boxplot = {}\n",
    "# Loop through date ranges and percentiles\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        df_aq = {}\n",
    "        # Loop through aquifer codes\n",
    "        for aq in aq_codes_10:\n",
    "            temp_df = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'] == aq_names_10[aq]]\n",
    "            df_metrics = {}\n",
    "            # Loop through metrics\n",
    "            for metric in metric_list:\n",
    "                metrics_desc = temp_df[metric].describe()\n",
    "                df_metrics[metric] = metrics_desc\n",
    "            df_aq[aq] = df_metrics\n",
    "        df_aq_boxplot[f'{date_range}_{percentile}'] = df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3d0674bf-6e83-4f92-872e-747c5e34a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_gages_boxplot\n",
    "# name = 'valid_gages'\n",
    "\n",
    "#data = df_huc2_boxplot\n",
    "#name = 'huc2'\n",
    "\n",
    "# data = df_aq_boxplot\n",
    "# name = 'aq'\n",
    "\n",
    "data = df_aq25_grouped_boxplot\n",
    "name = 'aq25_grouped'\n",
    "\n",
    "#data = df_aq10_grouped_boxplot\n",
    "#name = 'aq10_grouped'\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# Loop over the outer dictionary and convert each nested dictionary into a DataFrame\n",
    "for key, metrics in data.items():\n",
    "    # Convert the inner dictionary to a DataFrame\n",
    "    df = pd.DataFrame(metrics)\n",
    "    dfs[key] = df\n",
    "\n",
    "for date_range in date_ranges:\n",
    "    for percentile in percentiles:\n",
    "        file_name = f'boxplot_{name}_{date_range}_{percentile}.xlsx'\n",
    "        dfs[f'{date_range}_{percentile}'].to_excel('Tables/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9801234c-6dab-4987-b710-046e83510395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1690.000000\n",
       "mean       40.115056\n",
       "std         8.903198\n",
       "min         6.629630\n",
       "25%        36.464881\n",
       "50%        36.627315\n",
       "75%        40.555556\n",
       "max       156.428571\n",
       "Name: annual_duration, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range = '30'\n",
    "percentile = '90'\n",
    "temp_df = dfs_valid[f'{date_range}_{percentile}'][dfs_valid[f'{date_range}_{percentile}']['within_aq'].isin(aq_names_25_list)]\n",
    "temp_df['annual_duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c9b67-a463-4977-b6f5-63995db76ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
